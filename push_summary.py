import os
import openai
import requests
from datetime import datetime, timedelta
import feedparser
from urllib.parse import urlencode

# è·å–ç¯å¢ƒå˜é‡
NOTION_TOKEN = os.environ["NOTION_TOKEN"]
PAGE_ID = os.environ["PAGE_ID"]
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
QUERY_KEYWORDS = os.environ.get("QUERY_KEYWORDS", "medical imaging, segmentation, ultrasound, CT")

# åˆå§‹åŒ– GPT
openai.api_key = OPENAI_API_KEY
today = datetime.today()
today_fmt = today.strftime("%Yå¹´%mæœˆ")
past_date = (today - timedelta(days=30)).strftime("%Y-%m-%d")

# -------- STEP 1: æŠ“å– arXiv è®ºæ–‡ --------
def fetch_arxiv_papers(max_results=10):
    base_url = "http://export.arxiv.org/api/query"
    keywords = [kw.strip() for kw in QUERY_KEYWORDS.split(",")]
    raw_query = " OR ".join(keywords)
    query_params = {
        "search_query": f"all:{raw_query}",
        "start": 0,
        "max_results": max_results,
        "sortBy": "submittedDate",
        "sortOrder": "descending"
    }
    query_string = urlencode(query_params)
    feed_url = f"{base_url}?{query_string}"
    feed = feedparser.parse(feed_url)
    papers = []
    for entry in feed.entries:
        title = entry.title.strip().replace("\n", " ")
        date = entry.published.split("T")[0]
        link = entry.link
        papers.append(f"- [{date}] {title} ({link})")
    return papers

# -------- STEP 2: æ„é€  ChatGPT Prompt å¹¶è·å–æ‘˜è¦ --------
def generate_summary_from_papers(papers):
    papers_markdown = "\n".join(papers)
    prompt = f"""
ä»¥ä¸‹æ˜¯è¿‘ 30 å¤©å†…ä¸â€œ{QUERY_KEYWORDS}â€ç›¸å…³çš„ arXiv è®ºæ–‡åˆ—è¡¨ï¼Œè¯·æ ¹æ®å®ƒä»¬æ€»ç»“å½“å‰åŒ»å­¦å½±åƒç ”ç©¶çš„å…³é”®è¶‹åŠ¿ã€çƒ­ç‚¹æ–¹å‘å’Œç ”ç©¶å…³æ³¨ç‚¹ã€‚è¾“å‡ºè¯·ä½¿ç”¨ Markdownï¼Œå¹¶æŒ‰ä»¥ä¸‹æ ¼å¼ï¼š

## {today_fmt} åŒ»å­¦å½±åƒ arXiv çƒ­ç‚¹è®ºæ–‡æ€»ç»“

### ğŸ” è¶‹åŠ¿æ¦‚è§ˆ
ï¼ˆç”± GPT ç”Ÿæˆçš„æ€»ç»“ï¼‰

### ğŸ“„ è®ºæ–‡åˆ—è¡¨
{papers_markdown}
"""
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»å­¦å½±åƒç ”ç©¶åˆ†æåŠ©æ‰‹"},
            {"role": "user", "content": prompt}
        ]
    )
    return response["choices"][0]["message"]["content"]

# -------- STEP 3: æ¨é€åˆ° Notion --------
def push_to_notion(content):
    url = f"https://api.notion.com/v1/blocks/{PAGE_ID}/children"
    headers = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": "2022-06-28",
        "Content-Type": "application/json"
    }
    payload = {
        "children": [{
            "object": "block",
            "type": "paragraph",
            "paragraph": {
                "rich_text": [{
                    "type": "text",
                    "text": {"content": content}
                }]
            }
        }]
    }
    res = requests.patch(url, headers=headers, json=payload)
    print("Push result:", res.status_code, res.text)

# -------- ä¸»æµç¨‹ --------
if __name__ == "__main__":
    papers = fetch_arxiv_papers()
    summary = generate_summary_from_papers(papers)
    push_to_notion(summary)
